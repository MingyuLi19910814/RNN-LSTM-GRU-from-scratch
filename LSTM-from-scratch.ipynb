{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7270116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "806a1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 2\n",
    "SEQ_LEN = 1\n",
    "HIDDEN_SIZE = 2\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17e3db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = np.random.randn(BATCH_SIZE, SEQ_LEN, INPUT_SIZE).astype(np.float32)\n",
    "kernel = np.random.randn(INPUT_SIZE, HIDDEN_SIZE * 4).astype(np.float32)\n",
    "recurrent_kernel = np.random.randn(INPUT_SIZE, HIDDEN_SIZE * 4).astype(np.float32)\n",
    "bias = np.random.randn(HIDDEN_SIZE * 4).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88134dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.00261656  0.7161094 ]]\n",
      "\n",
      " [[-0.00569702  0.62866473]]\n",
      "\n",
      " [[-0.00151875  0.5827352 ]]\n",
      "\n",
      " [[-0.01549257  0.5073756 ]]], shape=(4, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def tf_lstm(input_, kernel_, recurrent_kernel_, bias_):\n",
    "    inputs = tf.keras.layers.Input(shape=(SEQ_LEN, INPUT_SIZE), dtype=tf.float32)\n",
    "    lstm_layer = tf.keras.layers.LSTM(HIDDEN_SIZE, return_sequences=True)\n",
    "    outputs = lstm_layer(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    lstm_layer.set_weights([kernel_, recurrent_kernel_, bias_])\n",
    "    return model(input_)\n",
    "\n",
    "tf_output = tf_lstm(input_tensor, kernel, recurrent_kernel, bias)\n",
    "print(tf_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df4e818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.00261656  0.7161094 ]]\n",
      "\n",
      " [[-0.00569702  0.62866473]]\n",
      "\n",
      " [[-0.00151875  0.5827352 ]]\n",
      "\n",
      " [[-0.01549257  0.5073756 ]]]\n"
     ]
    }
   ],
   "source": [
    "def scratch_lstm(input_, kernel_, recurrent_kernel_, bias_):\n",
    "    hidden_state = np.zeros((BATCH_SIZE, HIDDEN_SIZE), dtype=np.float32)\n",
    "    cell_state = np.zeros((BATCH_SIZE, HIDDEN_SIZE), dtype=np.float32)\n",
    "    output = np.zeros((BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE), dtype=np.float32)\n",
    "    w_i = kernel_[:, 0 * HIDDEN_SIZE: 1 * HIDDEN_SIZE]\n",
    "    w_f = kernel_[:, 1 * HIDDEN_SIZE: 2 * HIDDEN_SIZE]\n",
    "    w_c = kernel_[:, 2 * HIDDEN_SIZE: 3 * HIDDEN_SIZE]\n",
    "    w_o = kernel_[:, 3 * HIDDEN_SIZE: 4 * HIDDEN_SIZE]\n",
    "    r_i = recurrent_kernel_[:, 0 * HIDDEN_SIZE: 1 * HIDDEN_SIZE]\n",
    "    r_f = recurrent_kernel_[:, 1 * HIDDEN_SIZE: 2 * HIDDEN_SIZE]\n",
    "    r_c = recurrent_kernel_[:, 2 * HIDDEN_SIZE: 3 * HIDDEN_SIZE]\n",
    "    r_o = recurrent_kernel_[:, 3 * HIDDEN_SIZE: 4 * HIDDEN_SIZE]\n",
    "    b_i = bias_[0 * HIDDEN_SIZE: 1 * HIDDEN_SIZE]\n",
    "    b_f = bias_[1 * HIDDEN_SIZE: 2 * HIDDEN_SIZE]    \n",
    "    b_c = bias_[2 * HIDDEN_SIZE: 3 * HIDDEN_SIZE]\n",
    "    b_o = bias_[3 * HIDDEN_SIZE: 4 * HIDDEN_SIZE]\n",
    "    for seq_idx in range(SEQ_LEN):\n",
    "        forget_gate = tf.linalg.matmul(input_[:, seq_idx, :], w_f) + tf.linalg.matmul(hidden_state, r_f) + b_f\n",
    "        forget_gate = tf.math.sigmoid(forget_gate)\n",
    "        \n",
    "        input_gate = tf.linalg.matmul(input_[:, seq_idx, :], w_i) + tf.linalg.matmul(hidden_state, r_i) + b_i\n",
    "        input_gate = tf.math.sigmoid(input_gate)\n",
    "        \n",
    "        output_gate = tf.linalg.matmul(input_[:, seq_idx, :], w_o) + tf.linalg.matmul(hidden_state, r_o) + b_o\n",
    "        output_gate = tf.math.sigmoid(output_gate)\n",
    "        \n",
    "        cell_tmp = tf.linalg.matmul(input_[:, seq_idx, :], w_c) + tf.linalg.matmul(hidden_state, r_c) + b_c\n",
    "        cell_state = forget_gate * cell_state + input_gate * tf.math.tanh(cell_tmp)\n",
    "        \n",
    "        hidden_state = output_gate * tf.math.tanh(cell_state)\n",
    "        output[:, seq_idx, :] = hidden_state\n",
    "    return output\n",
    "\n",
    "scratch_output = scratch_lstm(input_tensor, kernel, recurrent_kernel, bias)\n",
    "print(scratch_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "407bbbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(tf_output.numpy(), scratch_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9bf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
