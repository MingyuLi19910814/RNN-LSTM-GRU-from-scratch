{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec45a05",
   "metadata": {},
   "source": [
    "# Unidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ff45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b469c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "BATCH_SIZE = 2\n",
    "SEQ_LEN = 3\n",
    "INPUT_SIZE = 4\n",
    "HIDDEN_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "275ab359",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = np.random.randn(BATCH_SIZE, SEQ_LEN, INPUT_SIZE).astype(np.float32)\n",
    "w_ih = np.random.randn(INPUT_SIZE, HIDDEN_SIZE).astype(np.float32)\n",
    "w_hh = np.random.randn(HIDDEN_SIZE, HIDDEN_SIZE).astype(np.float32)\n",
    "b = np.random.randn(HIDDEN_SIZE).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946d2f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.99367493 -0.9263422 ]\n",
      "  [-0.9670784  -0.9899978 ]\n",
      "  [-0.9992837  -0.9921832 ]]\n",
      "\n",
      " [[ 0.8910041  -0.02237447]\n",
      "  [ 0.75538677 -0.99566084]\n",
      "  [-0.99960285 -0.98956466]]], shape=(2, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def tf_unidirectional_rnn(input_, w_ih_, w_hh_, b_):\n",
    "    inputs = tf.keras.layers.Input(shape=(SEQ_LEN, INPUT_SIZE))\n",
    "    rnn_layer = tf.keras.layers.SimpleRNN(HIDDEN_SIZE, return_sequences=True)\n",
    "    outputs = rnn_layer(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    # set the initial weight of the RNN to be the same as the scratch\n",
    "    model.layers[1].set_weights([w_ih_, w_hh_, b_])\n",
    "    return model(input_)    \n",
    "\n",
    "tf_output = tf_unidirectional_rnn(input_tensor, w_ih, w_hh, b)\n",
    "print(tf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2684c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.99367493 -0.9263422 ]\n",
      "  [-0.9670784  -0.9899978 ]\n",
      "  [-0.9992837  -0.9921832 ]]\n",
      "\n",
      " [[ 0.8910041  -0.02237447]\n",
      "  [ 0.7553868  -0.99566084]\n",
      "  [-0.99960285 -0.98956466]]]\n"
     ]
    }
   ],
   "source": [
    "def scratch_unidirectional_rnn(input_, w_ih_, w_hh_, b_):\n",
    "    hidden = np.zeros(shape=(BATCH_SIZE, HIDDEN_SIZE)).astype(np.float32)\n",
    "    output = np.zeros(shape=(BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE)).astype(np.float32)\n",
    "    for seq_idx in range(SEQ_LEN):\n",
    "        hidden = tf.linalg.matmul(input_[:, seq_idx, :], w_ih_) + tf.linalg.matmul(hidden, w_hh_) + b_\n",
    "        hidden = tf.math.tanh(hidden)\n",
    "        output[:, seq_idx, :] = hidden\n",
    "    return output\n",
    "scratch_output = scratch_unidirectional_rnn(input_tensor, w_ih, w_hh, b)\n",
    "print(scratch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0944bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check whether the outputs of the two functions are very close\n",
    "print(np.allclose(tf_output.numpy(), scratch_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23f870",
   "metadata": {},
   "source": [
    "# Bidrectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab207c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ih_reverse = np.random.randn(INPUT_SIZE, HIDDEN_SIZE).astype(np.float32)\n",
    "w_hh_reverse = np.random.randn(HIDDEN_SIZE, HIDDEN_SIZE).astype(np.float32)\n",
    "b_reverse = np.random.randn(HIDDEN_SIZE).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b8ef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.99367493, -0.9263422 , -0.09472295, -0.07357155],\n",
       "        [-0.9670784 , -0.9899978 , -0.6786357 , -0.996604  ],\n",
       "        [-0.9992837 , -0.9921832 ,  0.8756912 ,  0.990144  ]],\n",
       "\n",
       "       [[ 0.8910041 , -0.02237447,  0.91867334,  0.41186035],\n",
       "        [ 0.75538677, -0.99566084, -0.7954552 , -0.9999865 ],\n",
       "        [-0.99960285, -0.98956466,  0.6120095 ,  0.99115074]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tf_bidirectional_rnn(input_, w_ih_, w_hh_, b_, w_ih_reverse_, w_hh_reverse_, b_reverse_):\n",
    "    inputs = tf.keras.layers.Input(shape=(SEQ_LEN, INPUT_SIZE), dtype=tf.float32)\n",
    "    rnn_layer = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(HIDDEN_SIZE, return_sequences=True))\n",
    "    outputs = rnn_layer(inputs)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=outputs)\n",
    "    rnn_layer.set_weights([w_ih_, w_hh_, b_, w_ih_reverse_, w_hh_reverse_, b_reverse_])\n",
    "    return model(input_)\n",
    "\n",
    "tf_output = tf_bidirectional_rnn(input_tensor, w_ih, w_hh, b, w_ih_reverse, w_hh_reverse, b_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7576cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.99367493, -0.9263422 , -0.09472291, -0.07357161],\n",
       "        [-0.9670784 , -0.9899978 , -0.6786357 , -0.996604  ],\n",
       "        [-0.9992837 , -0.9921832 ,  0.8756912 ,  0.990144  ]],\n",
       "\n",
       "       [[ 0.8910041 , -0.02237447,  0.91867334,  0.4118603 ],\n",
       "        [ 0.7553868 , -0.99566084, -0.7954552 , -0.9999865 ],\n",
       "        [-0.99960285, -0.98956466,  0.6120095 ,  0.99115074]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scratch_bidirectional_rnn(input_, w_ih_, w_hh_, b_, w_ih_reverse_, w_hh_reverse_, b_reverse_):\n",
    "    forward_output = scratch_unidirectional_rnn(input_, w_ih_, w_hh_, b_)\n",
    "    reversed_input = tf.reverse(input_, axis=[1])\n",
    "    backward_output = scratch_unidirectional_rnn(reversed_input, w_ih_reverse_, w_hh_reverse_, b_reverse_)\n",
    "    backward_output = tf.reverse(backward_output, axis=[1])\n",
    "    return tf.concat([forward_output, backward_output], axis=2)\n",
    "\n",
    "\n",
    "scratch_output = scratch_bidirectional_rnn(input_tensor, w_ih, w_hh, b, w_ih_reverse, w_hh_reverse, b_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0a48ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(tf_output, scratch_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79480504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
